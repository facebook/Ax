{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop API Example on Hartmann6\n",
    "\n",
    "The loop API is the most lightweight way to do optimization in Ax. The user makes one call to `optimize`, which performs all of the optimization under the hood and returns the optimized parameters.\n",
    "\n",
    "For more customizability of the optimization procedure, consider the Service or Developer API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "in_colab = 'google.colab' in sys.modules\n",
    "if in_colab:\n",
    "    %pip install ax-platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ax.metrics.branin import branin\n",
    "\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.measurement.synthetic_functions import hartmann6\n",
    "from ax.utils.notebook.plotting import init_notebook_plotting, render\n",
    "import plotly.io as pio\n",
    "\n",
    "init_notebook_plotting()\n",
    "if in_colab:\n",
    "    pio.renderers.default = \"colab\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define evaluation function\n",
    "\n",
    "First, we define an evaluation function that is able to compute all the metrics needed for this experiment. This function needs to accept a set of parameter values and can also accept a weight. It should produce a dictionary of metric names to tuples of mean and standard error for those metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hartmann_evaluation_function(parameterization):\n",
    "    x = np.array([parameterization.get(f\"x{i+1}\") for i in range(6)])\n",
    "    # In our case, standard error is 0, since we are computing a synthetic function.\n",
    "    return {\"hartmann6\": (hartmann6(x), 0.0), \"l2norm\": (np.sqrt((x**2).sum()), 0.0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is only one metric in the experiment – the objective – then evaluation function can return a single tuple of mean and SEM, in which case Ax will assume that evaluation corresponds to the objective. It can also return only the mean as a float, in which case Ax will treat SEM as unknown and use a model that can infer it. For more details on evaluation function, refer to the \"Trial Evaluation\" section in the docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run optimization\n",
    "The setup for the loop is fully compatible with JSON. The optimization algorithm is selected based on the properties of the problem search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=[\n",
    "        {\n",
    "            \"name\": \"x1\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [0.0, 1.0],\n",
    "            \"value_type\": \"float\",  # Optional, defaults to inference from type of \"bounds\".\n",
    "            \"log_scale\": False,  # Optional, defaults to False.\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"x2\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [0.0, 1.0],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"x3\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [0.0, 1.0],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"x4\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [0.0, 1.0],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"x5\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [0.0, 1.0],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"x6\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [0.0, 1.0],\n",
    "        },\n",
    "    ],\n",
    "    experiment_name=\"test\",\n",
    "    objective_name=\"hartmann6\",\n",
    "    evaluation_function=hartmann_evaluation_function,\n",
    "    minimize=True,  # Optional, defaults to False.\n",
    "    parameter_constraints=[\"x1 + x2 <= 20\"],  # Optional.\n",
    "    outcome_constraints=[\"l2norm <= 1.25\"],  # Optional.\n",
    "    total_trials=30,  # Optional.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can introspect optimization results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, covariances = values\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, minimum of Hartmann6 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hartmann6.fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot results\n",
    "Here we arbitrarily select \"x1\" and \"x2\" as the two parameters to plot for both metrics, \"hartmann6\" and \"l2norm\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(plot_contour(model=model, param_x=\"x1\", param_y=\"x2\", metric_name=\"hartmann6\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(plot_contour(model=model, param_x=\"x1\", param_y=\"x2\", metric_name=\"l2norm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also plot optimization trace, which shows best hartmann6 objective value seen by each iteration of the optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `plot_single_method` expects a 2-d array of means, because it expects to average means from multiple\n",
    "# optimization runs, so we wrap out best objectives array in another array.\n",
    "best_objectives = np.array(\n",
    "    [[trial.objective_mean for trial in experiment.trials.values()]]\n",
    ")\n",
    "best_objective_plot = optimization_trace_single_method(\n",
    "    y=np.minimum.accumulate(best_objectives, axis=1),\n",
    "    optimum=hartmann6.fmin,\n",
    "    title=\"Model performance vs. # of iterations\",\n",
    "    ylabel=\"Hartmann6\",\n",
    ")\n",
    "render(best_objective_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
