{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "30695db7-ed00-4802-a731-709b54b64c7e",
      "metadata": {},
      "source": [
        "> **⚠ INFO ⚠**\n",
        "> \n",
        "> This document discusses non-API components of Ax, which may be subject to backwards\n",
        "compatibility breaking changes between major library versions. This guide is primarily\n",
        "useful for researchers that indend to utilize custom BoTorch components for\n",
        "candidate generation in Ax. For most users, we recommend limiting the customization\n",
        "to the options that are exposed in `GenerationStrategyConfig`.\n",
        "\n",
        "\n",
        "# Utilizing custom Generators via Modular BoTorch Interface\n",
        "\n",
        "In Ax, we primarily utilize Bayesian optimization algorithms implemneted in BoTorch for candidate generation.\n",
        "While Ax offers a user-friendly API for experiment creation & orchestration, BoTorch implements a series of\n",
        "surrogate models, acquisition functions, optimizers and other utilities that primarily operate on PyTorch `Tensor`s.\n",
        "In a sense, Ax & BoTorch speak two different languages, and the Modular BoTorch Interface is the translation\n",
        "layer that allows them to communicate and operate together.\n",
        "\n",
        "## GenerationStrategy and the components of Ax's modeling layer\n",
        "\n",
        "Before diving into the specifics of Modular BoTorch, it is useful to provide brief context on how candidate\n",
        "generation happens in Ax. \n",
        "* The `GenerationStrategy` is the top level abstraction that specifies\n",
        "  + a series of `GenerationNode`s \n",
        "  + and some rules (`TransitionCriterion`) for transitioning between them.\n",
        "* Each `GenerationNode` specifies a `GeneratorSpec` (could be multiple, but that's beyond the scope),\n",
        "which contains a `Generators` registry entry that specifies \n",
        "  + an `Adapter` and `Generator` class to use,\n",
        "  + as well as any additional options to customize these objects.\n",
        "* At a high level, the `Adapter` classes handle the translation between \n",
        "  + the Ax data model (search space, trials, data) \n",
        "  + and the `Generator` classes, which typically operate on simplified, fully-numerical spaces. \n",
        "  + This is in part handled by the `Transform` classes, which can implement things like \n",
        "    - converting a string valued `ChoiceParameter` into a numerical parameter, \n",
        "    - log-transforming a log-scale `RangeParameter`, \n",
        "    - or standardizing the observations for a given metric.\n",
        "\n",
        "In this tutorial:\n",
        "* We will consider a setup similar to the default `GenerationStrategy`, where we transition from \n",
        "`CenterOfSearchSpace` to `Sobol` to `ModularBoTorch`.\n",
        "* We will be using `Generators.BOTORCH_MODULAR`, which combines \n",
        "  + the `TorchAdapter` and `BoTorchGenerator` classes (key component of the Modular BoTorch Interface),\n",
        "  + and a set of default transforms to convert the Ax search space & observations into all-numerical \n",
        "    valued inputs that are compatible with the BoTorch objects.\n",
        "\n",
        "\n",
        "Let's define a helper function that will construct the `GenerationStrategy` from a given `GeneratorSpec` input that\n",
        "we will construct later in the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "837543fb-1ba7-4b4d-a3db-6b39b646f789",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ax.generation_strategy.center_generation_node import CenterGenerationNode\n",
        "from ax.generation_strategy.transition_criterion import MinTrials\n",
        "from ax.generation_strategy.generation_strategy import GenerationStrategy\n",
        "from ax.generation_strategy.generation_node import GenerationNode\n",
        "from ax.generation_strategy.generator_spec import GeneratorSpec\n",
        "from ax.adapter.registry import Generators\n",
        "\n",
        "def construct_generation_strategy(\n",
        "    generator_spec: GeneratorSpec, node_name: str,\n",
        ") -> GenerationStrategy:\n",
        "    \"\"\"Constructs a Center + Sobol + Modular BoTorch `GenerationStrategy`\n",
        "    using the provided `generator_spec` for the Modular BoTorch node.\n",
        "    \"\"\"\n",
        "    botorch_node = GenerationNode(\n",
        "        name=node_name,\n",
        "        generator_specs=[generator_spec],\n",
        "    )\n",
        "    sobol_node = GenerationNode(\n",
        "        name=\"Sobol\",\n",
        "        generator_specs=[\n",
        "            GeneratorSpec(\n",
        "                generator_enum=Generators.SOBOL,\n",
        "                # Let's use model_kwargs to set the random seed.\n",
        "                model_kwargs={\"seed\": 0},\n",
        "            ),\n",
        "        ],\n",
        "        transition_criteria=[\n",
        "            # Transition to BoTorch node once there are 5 trials on the experiment.\n",
        "            MinTrials(\n",
        "                threshold=5,\n",
        "                transition_to=botorch_node.name,\n",
        "                use_all_trials_in_exp=True,\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    # Center node is a customized node that uses a simplified logic and has a\n",
        "    # built-in transition criteria that transitions after generating once.\n",
        "    center_node = CenterGenerationNode(next_node_name=sobol_node.name)\n",
        "    return GenerationStrategy(\n",
        "        name=f\"Center+Sobol+{node_name}\",\n",
        "        nodes=[center_node, sobol_node, botorch_node]\n",
        "    )\n",
        "\n",
        "# Let's construct the simplest version with all defaults.\n",
        "construct_generation_strategy(\n",
        "    generator_spec=GeneratorSpec(generator_enum=Generators.BOTORCH_MODULAR),\n",
        "    node_name=\"Modular BoTorch\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdb1d3f3-a33d-44c5-82f0-2989bbf356bc",
      "metadata": {},
      "source": [
        "## The Modular BoTorch Generator\n",
        "\n",
        "`BoTorchGenerator` is responsible for fitting surrogate models (including model selection), constructing acquisition functions,\n",
        "and optimizing the acquisition functions to generate candidates; using the inputs provided by `TorchAdapter`.\n",
        "`BoTorchGenerator` is a highly modular class that aims to balance user-friendliness with customizability. It implements\n",
        "dispatching logic at various places to select the appropriate surrogate model (single task, multi-task or multi-fidelity GP), \n",
        "acquisition function (`qLogNEI`, `qLogNEHVI`) and the optimizer, based on the properties of the (transformed) search space\n",
        "and optimization config. In this tutorial, we will be focusing on the customizability aspect of it.\n",
        "\n",
        "The `SurrogateSpec` is a container of inputs that can be used to specify which surrogate models to fit for which metrics, and \n",
        "additional inputs to use when constructing these surrogate models. The `ModelConfig` container specifies one surrogate model\n",
        "class and any additional inputs for it. If multiple `ModelConfig`s are specified in a `SurrogateSpec`, both surrogate models\n",
        "will be fit to the training data, and the best model will be selected according to the specified criteria. This is a recent\n",
        "feature that is still under active development.\n",
        "\n",
        "Let's construct an example that uses model selection between a relatively vanilla GP and a fancier option, using the \n",
        "same `ModelConfig`s for all metrics. Later in the tutorial we will also demonstrate how to implement custom BoTorch models \n",
        "and acquisition functions and make them compatible with the Modular BoTorch Generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76db2530-ea1c-4539-947b-a3009f6ac8dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from gpytorch.kernels import MaternKernel\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.models.transforms.input import Warp\n",
        "from botorch.models.map_saas import AdditiveMapSaasSingleTaskGP\n",
        "from ax.utils.stats.model_fit_stats import MSE\n",
        "from ax.generators.torch.botorch_modular.surrogate import SurrogateSpec, ModelConfig\n",
        "\n",
        "surrogate_spec = SurrogateSpec(\n",
        "    model_configs=[\n",
        "        # Select between two models:\n",
        "        # An additive mixture of relatively strong SAAS priors with input Warping.\n",
        "        # A relatively vanilla GP with a Matern kernel.\n",
        "        ModelConfig(\n",
        "            botorch_model_class=AdditiveMapSaasSingleTaskGP,\n",
        "            input_transform_classes=[Warp],\n",
        "            # Additional options for the model constructor. These need to be supported\n",
        "            # by the input constructor. We will see that below.\n",
        "            model_options={},\n",
        "        ),\n",
        "        ModelConfig(\n",
        "            botorch_model_class=SingleTaskGP,\n",
        "            covar_module_class=MaternKernel,\n",
        "            covar_module_options={\"nu\": 2.5},\n",
        "        ),\n",
        "    ],\n",
        "    eval_criterion=MSE,  # Select the model to use as the one that minimizes mean squared error.\n",
        "    allow_batched_models=False,  # Forces each metric to be modeled with an independent BoTorch model.\n",
        "    # If we wanted to specify different options for different metrics.\n",
        "    # metric_to_model_configs: dict[str, list[ModelConfig]]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba348328-44ac-45dc-8c0b-ae46124b233b",
      "metadata": {},
      "source": [
        "The surrogate model is one key component of Bayesian optimization, and the other one is the acquisition function.\n",
        "We can customize the acquisition function to use as well, and complete the Modular BoTorch Generator specification.\n",
        "\n",
        "Note that we do not currently support manually selecting the acquisition function optimizer to use. We use a dispatching\n",
        "logic that selects the appropriate optimizer from BoTorch based on the properties of the (transformed) search space.\n",
        "However, we support passing in options to customize the optimization budget and other inputs used by the optimizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b21926d3-d399-4308-b14d-fd4ca78f47f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from botorch.acquisition.logei import qLogNoisyExpectedImprovement\n",
        "\n",
        "generator_spec = GeneratorSpec(\n",
        "    generator_enum=Generators.BOTORCH_MODULAR,\n",
        "    model_kwargs={\n",
        "        \"surrogate_spec\": surrogate_spec,\n",
        "        \"botorch_acqf_class\": qLogNoisyExpectedImprovement,\n",
        "        # Can be used for additional inputs that are not constructed\n",
        "        # by default in Ax. We will demonstrate below.\n",
        "        \"acquisition_options\": {},\n",
        "    },\n",
        "    # We can specify various options for the optimizer here.\n",
        "    generator_gen_kwargs = {\n",
        "        \"model_gen_options\": {\n",
        "            \"optimizer_kwargs\": {\n",
        "                \"num_restarts\": 20,\n",
        "                \"sequential\": False,\n",
        "                \"options\": {\n",
        "                    \"batch_limit\": 5,\n",
        "                    \"maxiter\": 200,\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "    }\n",
        ")\n",
        "\n",
        "generation_strategy = construct_generation_strategy(\n",
        "    generator_spec=generator_spec,\n",
        "    node_name=\"BoTorch w/ Model Selection\",\n",
        ")\n",
        "generation_strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "958fe774-dc22-4635-a680-5a8823ad16b2",
      "metadata": {},
      "source": [
        "## Using the custom `GenerationStrategy` with `Client`.\n",
        "\n",
        "The custom `GenerationStrategy` usage, like much of the rest of this tutorial, is not considered a part of Ax API \n",
        "and does not come with API-level stability guarantees. However, we do expose some methods on `Client` to\n",
        "facilitate its usage with the other API components, to support advanced usage demonstrated here.\n",
        "\n",
        "See the [getting started](../getting_started/index.mdx) tutorial to learn more about `Client`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "821f48fa-33c9-4c68-b577-23b76ecedf12",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from ax.api.client import Client\n",
        "from ax.api.configs import RangeParameterConfig\n",
        "\n",
        "client = Client()\n",
        "\n",
        "# Define two float parameters x1, x2 in unit hypercube.\n",
        "range_parameters = [\n",
        "    RangeParameterConfig(\n",
        "        name=\"x1\", parameter_type=\"float\", bounds=(0, 1)\n",
        "    ),\n",
        "    RangeParameterConfig(\n",
        "        name=\"x2\", parameter_type=\"float\", bounds=(0, 1)\n",
        "    )\n",
        "]\n",
        "\n",
        "client.configure_experiment(parameters=range_parameters)\n",
        "\n",
        "metric_name = \"test_metric\"  # this name is used during the optimization loop\n",
        "objective = f\"-{metric_name}\"  # minimization is specified by the negative sign\n",
        "\n",
        "client.configure_optimization(objective=objective)\n",
        "\n",
        "\n",
        "def test_function(x1, x2):\n",
        "    # A made-up function.\n",
        "    return x1 ** 2.0 - (x2 + 5.0) ** 0.75 / 4.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "472e5a00-52b0-4a0b-bdc0-e112d56534c2",
      "metadata": {},
      "source": [
        "Let's configure the client to use our custom `GenerationStrategy`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229bdffd-00b0-4e6d-a450-c27bdf9e2ae3",
      "metadata": {},
      "outputs": [],
      "source": [
        "client.set_generation_strategy(\n",
        "    generation_strategy=generation_strategy,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26416a27-bd03-4abd-a475-23c53c88e75d",
      "metadata": {},
      "source": [
        "Run 10 trials to make sure it works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61008f97-577c-4e3f-8018-2c5cabd26a31",
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(10):\n",
        "    trials = client.get_next_trials(max_trials=1)\n",
        "    for index, parameters in trials.items():\n",
        "        result = test_function(**parameters)\n",
        "        client.complete_trial(trial_index=index, raw_data={\"test_metric\": result})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f59d60b-82dd-43f9-89df-d6a123f2c9ad",
      "metadata": {},
      "source": [
        "We can see that the trials were generated using the different `GenerationNode`s we have specified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "291cfd83-a4a3-4cd0-b6d2-adaec1777691",
      "metadata": {},
      "outputs": [],
      "source": [
        "client.summarize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f713f298-29d3-4d21-85e9-722475f6d471",
      "metadata": {},
      "source": [
        "## Using custom models and acquisition functions\n",
        "\n",
        "Many models and acquisition functions that are available in BoTorch implement input constructors that allow them to\n",
        "interface with the Modular BoTorch Generator. In this section, we will demonstrate the necessary steps to take to ensure\n",
        "compatibility for any custom classes you may want to implement.\n",
        "\n",
        "### Implementing a custom model\n",
        "\n",
        "For this tutorial, we implement a very simple GPyTorch `ExactGP` model that uses an RBF kernel (with ARD) and infers a homoskedastic noise level.\n",
        "\n",
        "Model definition is straightforward. Here we implement a GPyTorch `ExactGP` that inherits from `GPyTorchModel`; together these two superclasses add all the API calls that BoTorch expects in its various modules. \n",
        "\n",
        "For compatibility with Modular BoTorch Generator, the model class must implement `construct_inputs`, which is used to filter & extract the \n",
        "inputs necessary to construct the model from the inputs provided by Ax. The base `Model` class implements a very basic version of this,\n",
        "though a more capable implementation may be necessary depending on the specifics of the custom model class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "143671d6-8c84-4ecc-bf77-85f87e7a27b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "\n",
        "from botorch.models.gpytorch import GPyTorchModel\n",
        "from botorch.utils.datasets import SupervisedDataset\n",
        "from gpytorch.distributions import MultivariateNormal\n",
        "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "from gpytorch.means import ConstantMean\n",
        "from gpytorch.models import ExactGP\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class SimpleCustomGP(ExactGP, GPyTorchModel):\n",
        "\n",
        "    _num_outputs = 1  # to inform GPyTorchModel API\n",
        "\n",
        "    def __init__(self, train_X, train_Y, train_Yvar: Optional[Tensor] = None):\n",
        "        # NOTE: This ignores train_Yvar and uses inferred noise instead.\n",
        "        # squeeze output dim before passing train_Y to ExactGP\n",
        "        super().__init__(train_X, train_Y.squeeze(-1), GaussianLikelihood())\n",
        "        self.mean_module = ConstantMean()\n",
        "        self.covar_module = ScaleKernel(\n",
        "            base_kernel=RBFKernel(ard_num_dims=train_X.shape[-1]),\n",
        "        )\n",
        "        self.to(train_X)  # make sure we're on the right device/dtype\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "    @classmethod\n",
        "    def construct_inputs(\n",
        "        cls,\n",
        "        training_data: SupervisedDataset,\n",
        "        # Depending on the experiment setup, additional arguments may be passed in here.\n",
        "    ) -> dict[str, Tensor]:\n",
        "        return {\n",
        "            \"train_X\": training_data.X,\n",
        "            \"train_Y\": training_data.Y,\n",
        "            \"train_Yvar\": training_data.Yvar,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e81c98e0-db66-4b18-9814-563755a01eb0",
      "metadata": {},
      "source": [
        "In most cases, implementing the `construct_inputs` method should be sufficient to support the custom model class.\n",
        "For more complicated cases, a dispatcher case for `submodel_input_constructor` can be registered, which will allow\n",
        "further customization. A very simple example is provided here to demonstrate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b53bed96-6b38-4eb4-9855-dec14dab8c83",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Any\n",
        "from botorch.models.model import Model\n",
        "from ax.core.search_space import SearchSpaceDigest\n",
        "from ax.generators.torch.botorch_modular.surrogate import Surrogate, submodel_input_constructor\n",
        "\n",
        "@submodel_input_constructor.register(SimpleCustomGP)\n",
        "def _submodel_input_constructor_test(\n",
        "    botorch_model_class: type[Model],\n",
        "    model_config: ModelConfig,\n",
        "    dataset: SupervisedDataset,\n",
        "    search_space_digest: SearchSpaceDigest,\n",
        "    surrogate: Surrogate,\n",
        ") -> dict[str, Any]:\n",
        "    return botorch_model_class.construct_inputs(\n",
        "        training_data=dataset,\n",
        "        **model_config.model_options,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f5b1424-7065-4a93-bb0e-7e8d22d5a3d6",
      "metadata": {},
      "source": [
        "In some cases, the default model fitting logic may not be appropriate. For example, we may utilize a pre-trained surrogate model,\n",
        "in which case we may want to skip model fitting. Other cases may include models that do not utilize a `MarginalLogLikelihood` class\n",
        "from GPyTorch, in which case a custom model fitting routine may be registered. To customize, we can register a dispatcher case\n",
        "for the `fit_botorch_model` helper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34d8ddbb-805d-44bd-ac20-ac237676abf6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from botorch.fit import fit_gpytorch_mll\n",
        "from gpytorch.mlls.marginal_log_likelihood import MarginalLogLikelihood\n",
        "from ax.generators.torch.botorch_modular.utils import fit_botorch_model\n",
        "\n",
        "@fit_botorch_model.register(SimpleCustomGP)\n",
        "def _fit_botorch_model_test(\n",
        "    model: SimpleCustomGP,\n",
        "    mll_class: type[MarginalLogLikelihood],\n",
        "    mll_options: dict[str, Any] | None = None,\n",
        ") -> None:\n",
        "    \"\"\"Fit a GPyTorch based BoTorch model.\"\"\"\n",
        "    mll_options = mll_options or {}\n",
        "    mll = mll_class(likelihood=model.likelihood, model=model, **mll_options)\n",
        "    fit_gpytorch_mll(mll)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c185d44-4ebf-40fa-9908-2c29cbfee1c5",
      "metadata": {},
      "source": [
        "### Implementing a custom acquisition function\n",
        "\n",
        "Since the author of the tutorial wasn't feeling particularly creative, we will demonstrate this using a \"custom\" simple regret acquisition function.\n",
        "The key piece in compatibility with Modular BoTorch Generator is again an input constructor. Let's define the acquisition function and register\n",
        "the input constructor for it after.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5154db37-067c-4472-a8c1-4316aa5c3b52",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from botorch.acquisition.objective import PosteriorTransform, MCAcquisitionObjective\n",
        "from botorch.acquisition.monte_carlo import MCAcquisitionFunction\n",
        "from botorch.sampling.base import MCSampler\n",
        "\n",
        "class CustomSimpleRegret(MCAcquisitionFunction):\n",
        "    # See qSimpleRegret in BoTorch for a better implementation.\n",
        "    # This is simplified from the original implementation.\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: Model,\n",
        "        sampler: MCSampler | None = None,\n",
        "        objective: MCAcquisitionObjective | None = None,\n",
        "        posterior_transform: PosteriorTransform | None = None,\n",
        "        X_pending: Tensor | None = None,\n",
        "    ) -> None:\n",
        "        super().__init__(\n",
        "            model=model,\n",
        "            sampler=sampler,\n",
        "            objective=objective,\n",
        "            posterior_transform=posterior_transform,\n",
        "            X_pending=X_pending,\n",
        "        )\n",
        "\n",
        "    def forward(self, X: Tensor) -> Tensor:\n",
        "        samples, obj = self._get_samples_and_objectives(X=X)\n",
        "        return torch.mean(torch.amax(obj, dim=-1), dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ff1d79b-b8ba-4c6c-ae47-c1a65bd08de7",
      "metadata": {},
      "source": [
        "The input constructors job is to extract & filter any arguments necessary to construct the acquisition function from the list of arguments\n",
        "that are provided by the `Acquisition` class (in Ax). Only a small number of arguments are required to be supported by any given input constructor.\n",
        "Other arguments that are not handled by the input constructor will be ignored. Additional details and examples can be found in \n",
        "`botorch/acquisition/input_constructors.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379768e9-2875-4090-b41e-642f4a46b30b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from botorch.acquisition.input_constructors import (\n",
        "    acqf_input_constructor,\n",
        "    construct_inputs_qSimpleRegret,\n",
        ")\n",
        "from typing import Callable\n",
        "\n",
        "@acqf_input_constructor(CustomSimpleRegret)\n",
        "def construct_inputs_custom_simple_regret(\n",
        "    model: Model,\n",
        "    objective: MCAcquisitionObjective | None = None,\n",
        "    posterior_transform: PosteriorTransform | None = None,\n",
        "    X_pending: Tensor | None = None,\n",
        "    sampler: MCSampler | None = None,\n",
        "    constraints: list[Callable[[Tensor], Tensor]] | None = None,\n",
        "    X_baseline: Tensor | None = None,\n",
        ") -> dict[str, Any]:\n",
        "    return construct_inputs_qSimpleRegret(\n",
        "        model=model,\n",
        "        objective=objective,\n",
        "        posterior_transform=posterior_transform,\n",
        "        X_pending=X_pending,\n",
        "        sampler=sampler,\n",
        "        constraints=constraints,\n",
        "        X_baseline=X_baseline\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ce4231c-e150-4e75-bf99-12731422e5af",
      "metadata": {},
      "source": [
        "## Let's use the custom model and acquisition function\n",
        "\n",
        "We repeat the above example but with the custom model and acquisition function this time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a77f475b-dee6-41c7-b9af-d23775ac2b6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "generation_strategy = construct_generation_strategy(\n",
        "    generator_spec=GeneratorSpec(\n",
        "        generator_enum=Generators.BOTORCH_MODULAR,\n",
        "        model_kwargs={\n",
        "            \"surrogate_spec\": SurrogateSpec(\n",
        "                model_configs=[\n",
        "                    ModelConfig(\n",
        "                        botorch_model_class=SimpleCustomGP\n",
        "                    )\n",
        "                ]\n",
        "            ),\n",
        "            \"botorch_acqf_class\": CustomSimpleRegret\n",
        "        }\n",
        "    ),\n",
        "    node_name=\"BoTorch w/ Custom Components\"\n",
        ")\n",
        "\n",
        "client = Client()\n",
        "client.configure_experiment(parameters=range_parameters)\n",
        "client.configure_optimization(objective=objective)\n",
        "client.set_generation_strategy(generation_strategy=generation_strategy)\n",
        "\n",
        "for _ in range(10):\n",
        "    trials = client.get_next_trials(max_trials=1)\n",
        "    for index, parameters in trials.items():\n",
        "        result = test_function(**parameters)\n",
        "        client.complete_trial(trial_index=index, raw_data={\"test_metric\": result})\n",
        "\n",
        "client.summarize()\n"
      ]
    }
  ],
  "metadata": {
    "fileHeader": "",
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
