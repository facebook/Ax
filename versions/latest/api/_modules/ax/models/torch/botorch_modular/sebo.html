<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Ax · Adaptive Experimentation Platform</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Adaptive Experimentation Platform"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Ax · Adaptive Experimentation Platform"/><meta property="og:type" content="website"/><meta property="og:url" content="https://ax.dev//versions/latest/index.html"/><meta property="og:description" content="Adaptive Experimentation Platform"/><meta property="og:image" content="https://ax.dev//versions/latest/img/ax.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://ax.dev//versions/latest/img/ax.svg"/><link rel="shortcut icon" href="/versions/latest/img/favicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-139570076-1', 'auto');
              ga('send', 'pageview');
            </script><script type="text/javascript" src="https://cdn.plot.ly/plotly-latest.min.js"></script><script type="text/javascript" src="/versions/latest/js/plotUtils.js"></script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/versions/latest/js/mathjax.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS_SVG"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/versions/latest/js/scrollSpy.js"></script><link rel="stylesheet" href="/versions/latest/css/main.css"/><script src="/versions/latest/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/versions/latest/"><img class="logo" src="/versions/latest/img/ax_lockup_white.svg" alt="Ax"/><h2 class="headerTitleWithLogo">Ax</h2></a><a href="/versions/latest/versions.html"><h3>latest</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/versions/latest/docs/why-ax.html" target="_self">Docs</a></li><li class=""><a href="/versions/latest/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/versions/latest/api/" target="_self">API</a></li><li class=""><a href="https://github.com/facebook/Ax" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./"
src="/js/documentation_options.js">
</script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<h1>Source code for ax.models.torch.botorch_modular.sebo</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="c1"># pyre-strict</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">functools</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">logging</span><span class="w"> </span><span class="kn">import</span> <span class="n">Logger</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ax.core.search_space</span><span class="w"> </span><span class="kn">import</span> <span class="n">SearchSpaceDigest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ax.exceptions.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">AxWarning</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ax.models.torch.botorch_modular.acquisition</span><span class="w"> </span><span class="kn">import</span> <span class="n">Acquisition</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ax.models.torch.botorch_modular.optimizer_argparse</span><span class="w"> </span><span class="kn">import</span> <span class="n">optimizer_argparse</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ax.models.torch.botorch_modular.surrogate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Surrogate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ax.models.torch_base</span><span class="w"> </span><span class="kn">import</span> <span class="n">TorchOptConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ax.utils.common.logger</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_logger</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.acquisition</span><span class="w"> </span><span class="kn">import</span> <span class="n">AcquisitionFunction</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.multi_objective.logei</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">qLogNoisyExpectedHypervolumeImprovement</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.penalized</span><span class="w"> </span><span class="kn">import</span> <span class="n">L0Approximation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.deterministic</span><span class="w"> </span><span class="kn">import</span> <span class="n">GenericDeterministicModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelList</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">gen_batch_initial_conditions</span><span class="p">,</span>
    <span class="n">Homotopy</span><span class="p">,</span>
    <span class="n">HomotopyParameter</span><span class="p">,</span>
    <span class="n">LogLinearHomotopySchedule</span><span class="p">,</span>
    <span class="n">optimize_acqf_homotopy</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">SupervisedDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyre_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">assert_is_instance</span><span class="p">,</span> <span class="n">none_throws</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>

<span class="n">CLAMP_TOL</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">logger</span><span class="p">:</span> <span class="n">Logger</span> <span class="o">=</span> <span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="SEBOAcquisition">
<a class="viewcode-back" href="../../../../../models.html#ax.models.torch.botorch_modular.sebo.SEBOAcquisition">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SEBOAcquisition</span><span class="p">(</span><span class="n">Acquisition</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Implement the acquisition function of Sparsity Exploring Bayesian</span>
<span class="sd">    Optimization (SEBO).</span>

<span class="sd">    The SEBO is a hyperparameter-free method to simultaneously maximize a target</span>
<span class="sd">    objective and sparsity. When L0 norm is used, SEBO uses a novel differentiable</span>
<span class="sd">    relaxation based on homotopy continuation to efficiently optimize for sparsity.</span>
<span class="sd">    """</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">surrogate</span><span class="p">:</span> <span class="n">Surrogate</span><span class="p">,</span>
        <span class="n">search_space_digest</span><span class="p">:</span> <span class="n">SearchSpaceDigest</span><span class="p">,</span>
        <span class="n">torch_opt_config</span><span class="p">:</span> <span class="n">TorchOptConfig</span><span class="p">,</span>
        <span class="n">botorch_acqf_class</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">AcquisitionFunction</span><span class="p">],</span>
        <span class="n">options</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tkwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"dtype"</span><span class="p">:</span> <span class="n">surrogate</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">"device"</span><span class="p">:</span> <span class="n">surrogate</span><span class="o">.</span><span class="n">device</span><span class="p">}</span>
        <span class="n">options</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">options</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">options</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">penalty_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"penalty"</span><span class="p">,</span> <span class="s2">"L0_norm"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"target_point"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_point</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"please provide target point."</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparsity_threshold</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
            <span class="s2">"sparsity_threshold"</span><span class="p">,</span> <span class="n">surrogate</span><span class="o">.</span><span class="n">Xs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="c1"># construct determinsitic model for penalty term</span>
        <span class="c1"># pyre-fixme[4]: Attribute must be annotated.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deterministic_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_construct_penalty</span><span class="p">()</span>
        <span class="n">surrogate_f</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">surrogate</span><span class="p">)</span>
        <span class="c1"># we need to clamp the training data to the target point here as it may</span>
        <span class="c1"># be slightly off due to numerical issues.</span>
        <span class="n">X_sparse</span> <span class="o">=</span> <span class="n">clamp_to_target</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">surrogate_f</span><span class="o">.</span><span class="n">Xs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span>
            <span class="n">target_point</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">,</span>
            <span class="n">clamp_tol</span><span class="o">=</span><span class="n">CLAMP_TOL</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># update the training data in new surrogate</span>
        <span class="n">none_throws</span><span class="p">(</span><span class="n">surrogate_f</span><span class="o">.</span><span class="n">_training_data</span><span class="p">)</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">SupervisedDataset</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X_sparse</span><span class="p">,</span>
                <span class="n">Y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">deterministic_model</span><span class="p">(</span><span class="n">X_sparse</span><span class="p">),</span>
                <span class="n">Yvar</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X_sparse</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>  <span class="c1"># noiseless</span>
                <span class="n">feature_names</span><span class="o">=</span><span class="n">surrogate_f</span><span class="o">.</span><span class="n">training_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span>
                <span class="n">outcome_names</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">penalty_name</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># update the model in new surrogate</span>
        <span class="n">surrogate_f</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">ModelList</span><span class="p">(</span><span class="n">surrogate</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">deterministic_model</span><span class="p">)</span>
        <span class="c1"># update objective weights and thresholds in the torch config</span>
        <span class="n">torch_opt_config_sebo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform_torch_config</span><span class="p">(</span>
            <span class="n">torch_opt_config</span><span class="o">=</span><span class="n">torch_opt_config</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span>
        <span class="p">)</span>

        <span class="c1"># Change some options (note: we do not want to do this in-place)</span>
        <span class="k">if</span> <span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"cache_root"</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">"SEBO doesn't support `cache_root=True`. Changing it to `False`."</span><span class="p">,</span>
                <span class="n">AxWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">options</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">options</span><span class="p">,</span> <span class="s2">"cache_root"</span><span class="p">:</span> <span class="kc">False</span><span class="p">}</span>

        <span class="c1"># Instantiate the `botorch_acqf_class`. We need to modify `a` before doing this</span>
        <span class="c1"># (as it controls the L0 norm approximation) since the baseline will be pruned</span>
        <span class="c1"># when the acquisition function is created. With a=1e-6 the deterministic model</span>
        <span class="c1"># will be numerically close to the true L0 norm and we will select the</span>
        <span class="c1"># baseline according to the last homotopy step.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty_name</span> <span class="o">==</span> <span class="s2">"L0_norm"</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">deterministic_model</span><span class="o">.</span><span class="n">_f</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">surrogate</span><span class="o">=</span><span class="n">surrogate_f</span><span class="p">,</span>
            <span class="n">search_space_digest</span><span class="o">=</span><span class="n">search_space_digest</span><span class="p">,</span>
            <span class="n">torch_opt_config</span><span class="o">=</span><span class="n">torch_opt_config_sebo</span><span class="p">,</span>
            <span class="n">botorch_acqf_class</span><span class="o">=</span><span class="n">qLogNoisyExpectedHypervolumeImprovement</span><span class="p">,</span>
            <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># update objective threshold for deterministic model (penalty term)</span>
        <span class="c1"># pyre-fixme[29]: `Union[(self: TensorBase, indices: Union[None, slice[Any, A...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">acqf</span><span class="o">.</span><span class="n">ref_point</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparsity_threshold</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_objective_thresholds</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparsity_threshold</span>  <span class="c1"># pyre-ignore</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_construct_penalty</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GenericDeterministicModel</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Construct a penalty term as deterministic model to be included in</span>
<span class="sd">        SEBO acqusition function. Currently only L0 and L1 penalty are supported.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty_name</span> <span class="o">==</span> <span class="s2">"L0_norm"</span><span class="p">:</span>
            <span class="n">L0</span> <span class="o">=</span> <span class="n">L0Approximation</span><span class="p">(</span><span class="n">target_point</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">GenericDeterministicModel</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">L0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty_name</span> <span class="o">==</span> <span class="s2">"L1_norm"</span><span class="p">:</span>
            <span class="n">L1</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span>
                <span class="n">L1_norm_func</span><span class="p">,</span>
                <span class="n">init_point</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">GenericDeterministicModel</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">L1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">penalty_name</span><span class="si">}</span><span class="s2"> is not currently implemented."</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_transform_torch_config</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">torch_opt_config</span><span class="p">:</span> <span class="n">TorchOptConfig</span><span class="p">,</span>
        <span class="o">**</span><span class="n">tkwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TorchOptConfig</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Transform torch config to include penalty term (deterministic model) as</span>
<span class="sd">        an additional outcomes in BoTorch model.</span>
<span class="sd">        """</span>
        <span class="c1"># update objective weights by appending the weight -1 for sparsity objective.</span>
        <span class="n">objective_weights_sebo</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">torch_opt_config</span><span class="o">.</span><span class="n">objective_weights</span><span class="p">,</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">torch_opt_config</span><span class="o">.</span><span class="n">outcome_constraints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># update the shape of A matrix in outcome_constraints</span>
            <span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">none_throws</span><span class="p">(</span><span class="n">torch_opt_config</span><span class="o">.</span><span class="n">outcome_constraints</span><span class="p">)</span>
            <span class="n">outcome_constraints_sebo</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">A</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">b</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outcome_constraints_sebo</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">torch_opt_config</span><span class="o">.</span><span class="n">objective_thresholds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">objective_thresholds_sebo</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">torch_opt_config</span><span class="o">.</span><span class="n">objective_thresholds</span><span class="p">,</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">sparsity_threshold</span><span class="p">],</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">),</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># NOTE: The reference point will be inferred in the base class.</span>
            <span class="n">objective_thresholds_sebo</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># update pending observations (if not none) by appending an obs for</span>
        <span class="c1"># the new penalty outcome</span>
        <span class="n">pending_observations</span> <span class="o">=</span> <span class="n">torch_opt_config</span><span class="o">.</span><span class="n">pending_observations</span>
        <span class="k">if</span> <span class="n">torch_opt_config</span><span class="o">.</span><span class="n">pending_observations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pending_observations</span> <span class="o">=</span> <span class="n">torch_opt_config</span><span class="o">.</span><span class="n">pending_observations</span> <span class="o">+</span> <span class="p">[</span>
                <span class="n">torch_opt_config</span><span class="o">.</span><span class="n">pending_observations</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">]</span>

        <span class="k">return</span> <span class="n">TorchOptConfig</span><span class="p">(</span>
            <span class="n">objective_weights</span><span class="o">=</span><span class="n">objective_weights_sebo</span><span class="p">,</span>
            <span class="n">outcome_constraints</span><span class="o">=</span><span class="n">outcome_constraints_sebo</span><span class="p">,</span>
            <span class="n">objective_thresholds</span><span class="o">=</span><span class="n">objective_thresholds_sebo</span><span class="p">,</span>
            <span class="n">linear_constraints</span><span class="o">=</span><span class="n">torch_opt_config</span><span class="o">.</span><span class="n">linear_constraints</span><span class="p">,</span>
            <span class="n">fixed_features</span><span class="o">=</span><span class="n">torch_opt_config</span><span class="o">.</span><span class="n">fixed_features</span><span class="p">,</span>
            <span class="n">pending_observations</span><span class="o">=</span><span class="n">pending_observations</span><span class="p">,</span>
            <span class="n">model_gen_options</span><span class="o">=</span><span class="n">torch_opt_config</span><span class="o">.</span><span class="n">model_gen_options</span><span class="p">,</span>
            <span class="n">rounding_func</span><span class="o">=</span><span class="n">torch_opt_config</span><span class="o">.</span><span class="n">rounding_func</span><span class="p">,</span>
            <span class="n">opt_config_metrics</span><span class="o">=</span><span class="n">torch_opt_config</span><span class="o">.</span><span class="n">opt_config_metrics</span><span class="p">,</span>
            <span class="n">is_moo</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># SEBO adds an objective, so it'll always be MOO.</span>
        <span class="p">)</span>

<div class="viewcode-block" id="SEBOAcquisition.optimize">
<a class="viewcode-back" href="../../../../../models.html#ax.models.torch.botorch_modular.sebo.SEBOAcquisition.optimize">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">optimize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">search_space_digest</span><span class="p">:</span> <span class="n">SearchSpaceDigest</span><span class="p">,</span>
        <span class="n">inequality_constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fixed_features</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rounding_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">optimizer_options</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Generate a set of candidates via multi-start optimization. Obtains</span>
<span class="sd">        candidates and their associated acquisition function values.</span>

<span class="sd">        Args:</span>
<span class="sd">            n: The number of candidates to generate.</span>
<span class="sd">            search_space_digest: A ``SearchSpaceDigest`` object containing search space</span>
<span class="sd">                properties, e.g. ``bounds`` for optimization.</span>
<span class="sd">            inequality_constraints: A list of tuples (indices, coefficients, rhs),</span>
<span class="sd">                with each tuple encoding an inequality constraint of the form</span>
<span class="sd">                ``sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs``.</span>
<span class="sd">            fixed_features: A map `{feature_index: value}` for features that</span>
<span class="sd">                should be fixed to a particular value during generation.</span>
<span class="sd">            rounding_func: A function that post-processes an optimization</span>
<span class="sd">                result appropriately (i.e., according to `round-trip`</span>
<span class="sd">                transformations).</span>
<span class="sd">            optimizer_options: Options for the optimizer function, e.g. ``sequential``</span>
<span class="sd">                or ``raw_samples``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A three-element tuple containing an `n x d`-dim tensor of generated</span>
<span class="sd">            candidates, a tensor with the associated acquisition values, and a tensor</span>
<span class="sd">            with the weight for each candidate.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty_name</span> <span class="o">==</span> <span class="s2">"L0_norm"</span><span class="p">:</span>
            <span class="n">candidates</span><span class="p">,</span> <span class="n">expected_acquisition_value</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_optimize_with_homotopy</span><span class="p">(</span>
                    <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
                    <span class="n">search_space_digest</span><span class="o">=</span><span class="n">search_space_digest</span><span class="p">,</span>
                    <span class="n">inequality_constraints</span><span class="o">=</span><span class="n">inequality_constraints</span><span class="p">,</span>
                    <span class="n">fixed_features</span><span class="o">=</span><span class="n">fixed_features</span><span class="p">,</span>
                    <span class="n">rounding_func</span><span class="o">=</span><span class="n">rounding_func</span><span class="p">,</span>
                    <span class="n">optimizer_options</span><span class="o">=</span><span class="n">optimizer_options</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># if L1 norm use standard moo-opt</span>
            <span class="n">candidates</span><span class="p">,</span> <span class="n">expected_acquisition_value</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
                <span class="n">search_space_digest</span><span class="o">=</span><span class="n">search_space_digest</span><span class="p">,</span>
                <span class="n">inequality_constraints</span><span class="o">=</span><span class="n">inequality_constraints</span><span class="p">,</span>
                <span class="n">fixed_features</span><span class="o">=</span><span class="n">fixed_features</span><span class="p">,</span>
                <span class="n">rounding_func</span><span class="o">=</span><span class="n">rounding_func</span><span class="p">,</span>
                <span class="n">optimizer_options</span><span class="o">=</span><span class="n">optimizer_options</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># similar, make sure if applies to sparse dimensions only</span>
        <span class="n">candidates</span> <span class="o">=</span> <span class="n">clamp_to_target</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">candidates</span><span class="p">,</span> <span class="n">target_point</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">,</span> <span class="n">clamp_tol</span><span class="o">=</span><span class="n">CLAMP_TOL</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">candidates</span><span class="p">,</span> <span class="n">expected_acquisition_value</span><span class="p">,</span> <span class="n">weights</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_optimize_with_homotopy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">search_space_digest</span><span class="p">:</span> <span class="n">SearchSpaceDigest</span><span class="p">,</span>
        <span class="n">inequality_constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fixed_features</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rounding_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">optimizer_options</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Optimize SEBO ACQF with L0 norm using homotopy."""</span>
        <span class="n">optimizer_options</span> <span class="o">=</span> <span class="n">optimizer_options</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="c1"># extend to fixed a no homotopy_schedule schedule</span>
        <span class="n">_tensorize</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">bounds</span> <span class="o">=</span> <span class="n">_tensorize</span><span class="p">(</span><span class="n">search_space_digest</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="n">homotopy_schedule</span> <span class="o">=</span> <span class="n">LogLinearHomotopySchedule</span><span class="p">(</span>
            <span class="n">start</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
            <span class="n">end</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
            <span class="n">num_steps</span><span class="o">=</span><span class="n">optimizer_options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"num_homotopy_steps"</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Prepare arguments for optimizer</span>
        <span class="n">optimizer_options_with_defaults</span> <span class="o">=</span> <span class="n">optimizer_argparse</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">acqf</span><span class="p">,</span>
            <span class="n">optimizer_options</span><span class="o">=</span><span class="n">optimizer_options</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="s2">"optimize_acqf_homotopy"</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">homotopy</span> <span class="o">=</span> <span class="n">Homotopy</span><span class="p">(</span>
            <span class="n">homotopy_parameters</span><span class="o">=</span><span class="p">[</span>
                <span class="n">HomotopyParameter</span><span class="p">(</span>
                    <span class="n">parameter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">deterministic_model</span><span class="o">.</span><span class="n">_f</span><span class="o">.</span><span class="n">a</span><span class="p">,</span>
                    <span class="n">schedule</span><span class="o">=</span><span class="n">homotopy_schedule</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">],</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="s2">"batch_initial_conditions"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">optimizer_options_with_defaults</span><span class="p">:</span>
            <span class="n">optimizer_options_with_defaults</span><span class="p">[</span><span class="s2">"batch_initial_conditions"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">get_batch_initial_conditions</span><span class="p">(</span>
                    <span class="n">acq_function</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">acqf</span><span class="p">,</span>
                    <span class="n">raw_samples</span><span class="o">=</span><span class="n">optimizer_options_with_defaults</span><span class="p">[</span><span class="s2">"raw_samples"</span><span class="p">],</span>
                    <span class="n">inequality_constraints</span><span class="o">=</span><span class="n">inequality_constraints</span><span class="p">,</span>
                    <span class="n">fixed_features</span><span class="o">=</span><span class="n">fixed_features</span><span class="p">,</span>
                    <span class="n">X_pareto</span><span class="o">=</span><span class="n">assert_is_instance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acqf</span><span class="o">.</span><span class="n">X_baseline</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">),</span>
                    <span class="n">target_point</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">,</span>
                    <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
                    <span class="n">num_restarts</span><span class="o">=</span><span class="n">optimizer_options_with_defaults</span><span class="p">[</span><span class="s2">"num_restarts"</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="n">candidates</span><span class="p">,</span> <span class="n">expected_acquisition_value</span> <span class="o">=</span> <span class="n">optimize_acqf_homotopy</span><span class="p">(</span>
            <span class="n">q</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
            <span class="n">acq_function</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">acqf</span><span class="p">,</span>
            <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
            <span class="n">homotopy</span><span class="o">=</span><span class="n">homotopy</span><span class="p">,</span>
            <span class="n">num_restarts</span><span class="o">=</span><span class="n">optimizer_options_with_defaults</span><span class="p">[</span><span class="s2">"num_restarts"</span><span class="p">],</span>
            <span class="n">raw_samples</span><span class="o">=</span><span class="n">optimizer_options_with_defaults</span><span class="p">[</span><span class="s2">"raw_samples"</span><span class="p">],</span>
            <span class="n">inequality_constraints</span><span class="o">=</span><span class="n">inequality_constraints</span><span class="p">,</span>
            <span class="n">post_processing_func</span><span class="o">=</span><span class="n">rounding_func</span><span class="p">,</span>
            <span class="n">fixed_features</span><span class="o">=</span><span class="n">fixed_features</span><span class="p">,</span>
            <span class="n">batch_initial_conditions</span><span class="o">=</span><span class="n">optimizer_options_with_defaults</span><span class="p">[</span>
                <span class="s2">"batch_initial_conditions"</span>
            <span class="p">],</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">candidates</span><span class="p">,</span>
            <span class="n">expected_acquisition_value</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">candidates</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">candidates</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
        <span class="p">)</span></div>



<div class="viewcode-block" id="L1_norm_func">
<a class="viewcode-back" href="../../../../../models.html#ax.models.torch.botorch_modular.sebo.L1_norm_func">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">L1_norm_func</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">init_point</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""L1_norm takes in a a `batch_shape x n x d`-dim input tensor `X`</span>
<span class="sd">    to a `batch_shape x n x 1`-dimensional L1 norm tensor. To be used</span>
<span class="sd">    for constructing a GenericDeterministicModel.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">init_point</span><span class="p">),</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>



<div class="viewcode-block" id="clamp_to_target">
<a class="viewcode-back" href="../../../../../models.html#ax.models.torch.botorch_modular.sebo.clamp_to_target">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">clamp_to_target</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">target_point</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">clamp_tol</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Clamp generated candidates within the given ranges to the target point.</span>

<span class="sd">    Args:</span>
<span class="sd">        X: A `batch_shape x n x d`-dim input tensor `X`.</span>
<span class="sd">        target_point: A tensor of size `d` corresponding to the target point.</span>
<span class="sd">        clamp_tol: The clamping tolerance. Any value within `clamp_tol` of the</span>
<span class="sd">            `target_point` will be clamped to the `target_point`.</span>
<span class="sd">    """</span>
    <span class="n">clamp_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">target_point</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">clamp_tol</span>
    <span class="n">X</span><span class="p">[</span><span class="n">clamp_mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">target_point</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)[</span><span class="n">clamp_mask</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">X</span></div>



<div class="viewcode-block" id="get_batch_initial_conditions">
<a class="viewcode-back" href="../../../../../models.html#ax.models.torch.botorch_modular.sebo.get_batch_initial_conditions">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_batch_initial_conditions</span><span class="p">(</span>
    <span class="n">acq_function</span><span class="p">:</span> <span class="n">AcquisitionFunction</span><span class="p">,</span>
    <span class="n">raw_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">X_pareto</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">target_point</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">num_restarts</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">inequality_constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">fixed_features</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Generate starting points for the SEBO acquisition function optimization."""</span>
    <span class="n">tkwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"device"</span><span class="p">:</span> <span class="n">X_pareto</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="s2">"dtype"</span><span class="p">:</span> <span class="n">X_pareto</span><span class="o">.</span><span class="n">dtype</span><span class="p">}</span>
    <span class="n">num_rand</span> <span class="o">=</span> <span class="n">num_restarts</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_pareto</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">num_restarts</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">num_local</span> <span class="o">=</span> <span class="n">num_restarts</span> <span class="o">-</span> <span class="n">num_rand</span>

    <span class="c1"># (1) Random points (Sobol if no constraints, otherwise uses hit-and-run)</span>
    <span class="n">X_cand_rand</span> <span class="o">=</span> <span class="n">gen_batch_initial_conditions</span><span class="p">(</span>
        <span class="n">acq_function</span><span class="o">=</span><span class="n">acq_function</span><span class="p">,</span>
        <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
        <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">raw_samples</span><span class="o">=</span><span class="n">raw_samples</span><span class="p">,</span>
        <span class="n">num_restarts</span><span class="o">=</span><span class="n">num_rand</span><span class="p">,</span>
        <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">"topn"</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span>
        <span class="n">fixed_features</span><span class="o">=</span><span class="n">fixed_features</span><span class="p">,</span>
        <span class="n">inequality_constraints</span><span class="o">=</span><span class="n">inequality_constraints</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">num_local</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">X_cand_rand</span>

    <span class="c1"># (2) Perturbations of points on the Pareto frontier (done by TuRBO/Spearmint)</span>
    <span class="n">X_cand_local</span> <span class="o">=</span> <span class="n">X_pareto</span><span class="o">.</span><span class="n">clone</span><span class="p">()[</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">high</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X_pareto</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">raw_samples</span><span class="p">,))</span>
    <span class="p">]</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">X_cand_local</span> <span class="o">!=</span> <span class="n">target_point</span>
    <span class="n">X_cand_local</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span>
        <span class="mf">0.2</span> <span class="o">*</span> <span class="p">((</span><span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">X_cand_local</span><span class="p">))[</span><span class="n">mask</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">X_cand_local</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">X_cand_local</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="nb">min</span><span class="o">=</span><span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">max</span><span class="o">=</span><span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">X_cand_local</span> <span class="o">=</span> <span class="n">X_cand_local</span><span class="p">[</span><span class="n">acq_function</span><span class="p">(</span><span class="n">X_cand_local</span><span class="p">)</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">num_local</span><span class="p">)</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">X_cand_rand</span><span class="p">,</span> <span class="n">X_cand_local</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>

</pre></div>
</div>
</div>
</div>
<div aria-label="Main" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../index.html">Ax</a></h1>
<search id="searchbox" role="search" style="display: none">
<div class="searchformwrapper">
<form action="../../../../../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" autocapitalize="off" autocomplete="off" autocorrect="off" name="q" placeholder="Search" spellcheck="false" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../analysis.html">ax.analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ax.html">ax</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../benchmark.html">ax.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../core.html">ax.core</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../early_stopping.html">ax.early_stopping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../exceptions.html">ax.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../global_stopping.html">ax.global_stopping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../health_check.html">ax.health_check</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../metrics.html">ax.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../modelbridge.html">ax.modelbridge</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../models.html">ax.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../plot.html">ax.plot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../preview.html">ax.preview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../runners.html">ax.runners</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../service.html">ax.service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../storage.html">ax.storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../utils.html">ax.utils</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../../../../../index.html">Documentation overview</a><ul>
<li><a href="../../../../index.html">Module code</a><ul>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div></section><a href="https://code.facebook.com/projects/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/versions/latest/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright">Copyright © 2025 Meta Platforms, Inc.</section></footer></div></body></html>